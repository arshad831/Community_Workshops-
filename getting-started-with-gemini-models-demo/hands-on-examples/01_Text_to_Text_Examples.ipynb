{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Text Generation Examples using Gemini Pro Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isham993/Desktop/Programming-Tutorials/decoding-data-science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isham993/mambaforge/envs/google_gemini_environment/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_AI_STUDIO = os.getenv(\"GOOGLE_AI_STUDIO\")\n",
    "GEMINI_PRO = os.getenv(\"GEMINI_PRO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Google AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_AI_STUDIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n",
      "models/embedding-001\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(GEMINI_PRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " genai.GenerativeModel(\n",
       "   model_name='models/gemini-pro',\n",
       "   generation_config={}.\n",
       "   safety_settings={}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.2 ms, sys: 10 ms, total: 17.2 ms\n",
      "Wall time: 8.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"Explain fibonacci sequence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Fibonacci Sequence:**\n",
      "The Fibonacci sequence is a series of numbers in which each number (Fibonacci number) is the sum of the two preceding numbers. Typically, the sequence starts with 0 and 1, although some variations may begin with different initial values.\n",
      "\n",
      "- **Recursive Definition:**\n",
      "\n",
      " F(n) = F(n-1) + F(n-2) for n > 1\n",
      " F(0) = 0\n",
      " F(1) = 1\n",
      "\n",
      "- **Explicit Formula:**\n",
      "\n",
      " F(n) = (φ^n - ψ^n) / √5\n",
      "where φ = (1 + √5) / 2 (the golden ratio)\n",
      "      ψ = (1 - √5) / 2\n",
      "\n",
      "- **General Properties:**\n",
      "\n",
      "  - Every third number in the sequence is even, starting from 0.\n",
      "  - Every Fibonacci number is divisible by its previous number.\n",
      "  - The ratio of consecutive Fibonacci numbers approaches the golden ratio (φ) as n becomes large.\n",
      "  - The Fibonacci sequence can be found in various natural phenomena and artistic patterns.\n",
      "\n",
      "- **Applications:**\n",
      "\n",
      "  - Mathematics: Number theory, probability, graph theory, and other mathematical concepts.\n",
      "  - Biology: Plant growth, leaf arrangement, and the structure of some organisms.\n",
      "  - Art and Design: Creating aesthetically pleasing patterns, spirals, and geometric designs.\n",
      "  - Computer Science: Algorithms, optimization techniques, and data structures.\n",
      "  - Economics and Finance: Forecasting market trends and analyzing financial data.\n",
      "\n",
      "- **Examples of the Fibonacci Sequence:**\n",
      "\n",
      "  - The initial values for the Fibonacci sequence are F(0) = 0 and F(1) = 1.\n",
      "  - The next few numbers in the sequence are: 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, ...\n",
      "  - The Fibonacci sequence can be visualized using the Fibonacci spiral, where each square's side length is a Fibonacci number.\n",
      "\n",
      "The Fibonacci sequence's beauty and mathematical properties have fascinated mathematicians, artists, and scientists for centuries. Its applications span various fields, demonstrating the interconnectedness of different disciplines in our world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 ms, sys: 5.75 ms, total: 9.19 ms\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"Write a poem on Elon Musk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a realm where dreams collide,\n",
      "A visionary, fierce and bold,\n",
      "Elon Musk, a name so wide,\n",
      "A pioneer with tales untold.\n",
      "\n",
      "From humble roots, he dared to soar,\n",
      "A maverick with a restless mind,\n",
      "He chased the stars, forevermore,\n",
      "Leaving earthly bounds behind.\n",
      "\n",
      "With PayPal, he reshaped the norm,\n",
      "Digital payments, swift and secure,\n",
      "He broke the mold, transformed the form,\n",
      "A world of commerce, brave and pure.\n",
      "\n",
      "Tesla Motors, his electric ride,\n",
      "A spark that set the future free,\n",
      "Zero emissions, a greener stride,\n",
      "A legacy for all to see\n",
      "\n",
      "SpaceX, his cosmic aspiration,\n",
      "To conquer stars, beyond our reach,\n",
      "Rockets that dance with grace and passion,\n",
      "A symphony of human speech.\n",
      "\n",
      "Neuralink, his mind-meld endeavor,\n",
      "A bridge between man and machine,\n",
      "Thought control, a new forever,\n",
      "Where dreams and reality convene.\n",
      "\n",
      "Hyperloop, his tubular dream,\n",
      "High-speed travel, swift and sleek,\n",
      "Vacuum tubes, a futuristic gleam,\n",
      "Connecting cities, like a streak.\n",
      "\n",
      "The Boring Company, his subterranean quest,\n",
      "Tunnels deep, a rapid flow,\n",
      "A world unseen, beneath our breast,\n",
      "A transit system, bright and aglow.\n",
      "\n",
      "A polymath, with boundless wit,\n",
      "A futurist, with eyes so keen,\n",
      "He pushes limits, breaks the bit,\n",
      "A modern-day renaissance machine.\n",
      "\n",
      "Some call him mad, a dreamer wild,\n",
      "A dreamer who dabbles in the dark,\n",
      "But he's a visionary, undefiled,\n",
      "Who lights the way, like a guiding spark.\n",
      "\n",
      "With triumphs and setbacks, he perseveres,\n",
      "A phoenix rising from the flame,\n",
      "He fails and learns, he conquers fears,\n",
      "A testament to his boundless name.\n",
      "\n",
      "So let us watch, with bated breath,\n",
      "As Elon Musk reshapes our fate,\n",
      "With every step, he breaks the tether,\n",
      "A pioneer, truly great.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the safety ratings of the response using attribute `.prompt_feedback`. We can see this to see when our responses get blocked or not due to safety concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 ms, sys: 4.06 ms, total: 6.16 ms\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"How to insult someone?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/google_gemini_environment/lib/python3.11/site-packages/google/generativeai/types/generation_types.py:254\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A quick accessor equivalent to `self.candidates[0].parts[0].text`\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m        ValueError: If the candidate list or parts list does not contain exactly one entry.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parts[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.text` quick accessor only works for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple (single-`Part`) text responses. This response \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m         )\n",
      "File \u001b[0;32m~/mambaforge/envs/google_gemini_environment/lib/python3.11/site-packages/google/generativeai/types/generation_types.py:234\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.parts` quick accessor only works for a single candidate, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidates) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.parts` quick accessor only works with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle candidate. With multiple candidates use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult.candidates[index].text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked."
     ]
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "block_reason: SAFETY\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: MEDIUM\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from general generation config such as temperature, max_tokens etc, we can even configure safety settings of the model. \n",
    "\n",
    "Details can be found here: https://ai.google.dev/docs/safety_setting_gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.9,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 4096,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=GEMINI_PRO,\n",
    "                              generation_config=generation_config,\n",
    "                              safety_settings=safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 ms, sys: 4.36 ms, total: 7.09 ms\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"How to insult someone?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is not appropriate to insult people. Insults are hurtful and can cause emotional pain. If you have a problem with someone, it is best to try to resolve it in a respectful manner.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: MEDIUM\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also, prompt the model in parts as a list. This technique is known as Chain of Verification and is one of the ways to reduce hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monaco is the most densely populated country in the world, with a population density of 18,678 people per square kilometer. The capital of Monaco is Monaco-Ville.\n"
     ]
    }
   ],
   "source": [
    "prompt_parts = [\n",
    "  \"Which is the most densely populated country?\",\n",
    "  \"What is the capital of that country?\",\n",
    "]\n",
    "\n",
    "\n",
    "response = model.generate_content(prompt_parts)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also allows to save the conversation in form of json internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=GEMINI_PRO)\n",
    "\n",
    "\n",
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.generativeai.types.generation_types.GenerateContentResponse at 0x10b250190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message(\"Who is the highest paid football player in the world?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the response using `chat.last.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kylian Mbappé'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.last.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.generativeai.types.generation_types.GenerateContentResponse at 0x10b6bee90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send_message(\"Who is the highest paid cricket player in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Virat Kohli'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.last.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the whole history using `chat.history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parts {\n",
       "   text: \"Who is the highest paid football player in the world?\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"Kylian Mbappé\"\n",
       " }\n",
       " role: \"model\",\n",
       " parts {\n",
       "   text: \"Who is the highest paid cricket player in the world?\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"Virat Kohli\"\n",
       " }\n",
       " role: \"model\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming of response allows the results to display in chunks as it is generated, and model will return the result in chunks as they are generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Reasons to Watch Interstellar:**\n",
      "\n",
      "1. **Stunning Visuals:** Inters\n",
      "tellar boasts breathtaking cinematography and CGI effects that transport viewers into the vastness of space and the wonders of the universe.\n",
      "\n",
      "2. **Thought-Provoking\n",
      " Story:** The film explores complex themes of love, family, time, and the nature of reality through its captivating narrative.\n",
      "\n",
      "3. **Scientific Accuracy:** Interstellar collaborated with theoretical physicist Kip Thorne to ensure that the science depicted in the film is accurate and plausible, making it an immersive experience for science enthusiasts.\n",
      "\n",
      "4\n",
      ". **Emotional Depth:** The film features powerful performances from Matthew McConaughey, Anne Hathaway, and other cast members, who bring emotional depth and realism to their characters.\n",
      "\n",
      "5. **Inspiring Message:** Interstellar conveys a message of hope, perseverance, and the indomitable spirit of humanity in the face of adversity.\n",
      "\n",
      "6. **Musical Score:** Composer Hans Zimmer's iconic score perfectly complements the film's visuals and emotional journey, enhancing the overall cinematic experience.\n",
      "\n",
      "7. **Director Christopher Nolan's Vision:** Known for his intricate and thought-provoking films, Christopher Nolan's direction in Interstellar showcases his unique\n",
      " style and ability to craft immersive cinematic experiences.\n",
      "\n",
      "8. **Critical Acclaim:** Interstellar received critical acclaim for its visuals, story, performances, and overall cinematic achievements, earning nominations for several awards, including Best Picture and Best Original Score at the Academy Awards.\n",
      "\n",
      "9. **Box Office Success:** The film was a commercial success, grossing over $675 million worldwide, demonstrating its popularity among audiences worldwide.\n",
      "\n",
      "10. **Long-Lasting Impact:** Interstellar has been praised for its ability to spark conversations about science, space exploration, and the mysteries of the universe, leaving a lasting impression on viewers.\n",
      "\n",
      "**Potential Downsides to Consider:**\n",
      "\n",
      "1. **Complex Storyline:** Some viewers may find the film's intricate plot and scientific concepts challenging to follow.\n",
      "\n",
      "2. **Length:** Interstellar is a lengthy film, clocking in at over two hours and thirty minutes, which can be a commitment for some viewers.\n",
      "\n",
      "3. **Emotional Intensity:** The film's emotional depth and themes may resonate strongly with some viewers, leading to a powerful but potentially overwhelming experience.\n",
      "\n",
      "Ultimately, whether or not you should watch Interstellar depends on your preferences and willingness to engage with a thought-provoking and visually stunning film. It's\n",
      " a movie that demands attention and reflection but offers a rewarding and unforgettable cinematic journey.\n",
      "CPU times: user 20.3 ms, sys: 12.3 ms, total: 32.6 ms\n",
      "Wall time: 7.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"Should I watch the movie 'Interstellar'.\", stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_experiment_mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
