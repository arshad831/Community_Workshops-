{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Question And Answering using Gemini Pro Vision Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Only video frames is supported at the moment based on which questions can be asked and model will answer based on the frames of the video. Audio is not supported.\n",
    "\n",
    "For now, videos are required to uploaded to Google Cloud Storage and will work on publicly available link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isham993/Desktop/Programming-Tutorials/decoding-data-science/getting-started-with-gemini-models-demo\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import (\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    ")\n",
    "from google.oauth2 import service_account  # importing auth using service_account\n",
    "import json\n",
    "\n",
    "import os\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate Google Service Account Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"), \"r\") as source:\n",
    "    info = json.load(source)\n",
    "    service_account.Credentials.from_service_account_info(info)\n",
    "\n",
    "GEMINI_PRO_VISION = os.getenv(\"GEMINI_PRO_VISION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(GEMINI_PRO_VISION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_to_data(file_path: str, mime_type: str):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        data = base64.b64encode(file.read())\n",
    "        file_data = Part.from_data(data=base64.b64decode(data), mime_type=mime_type)\n",
    "        return file_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting JSON Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets ask question to the video showcasing the profession of the person and other details.\n",
    "\n",
    "<video width=\"500\" height=\"500\" controls>\n",
    "  <source src=\"./person_doing_something.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      " ```json\n",
      "{\n",
      "  \"profession\": \"detective\",\n",
      "  \"action\": \"inspecting a document with a magnifying glass\",\n",
      "  \"city\": \"not possible to tell\"\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "What is the profession of the main person?\n",
    "What is he doing he doing exactly?\n",
    "Which city was this recorded in?\n",
    "Provide the answer JSON.\n",
    "\"\"\"\n",
    "video = convert_file_to_data(\n",
    "    file_path=\"./artifacts/sample_videos/person_doing_something.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting tags of objects throughout the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of video url in Google Storage:\n",
    "\n",
    "- `file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"`\n",
    "- `video_url = f\"https://storage.googleapis.com/{file_path}\"`\n",
    "\n",
    "The model only accepts uri for videos at this point. \n",
    "- `video_uri = f\"gs://{file_path}\"`\n",
    "\n",
    "So, `https://storage.googleapis.com/` will be replaced with `gs://` when passing to `Part.from_uri` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini pro vision model also is able to extract tags from video. Lets see how it does for the following video. \n",
    "\n",
    "<video width=\"500\" height=\"500\" controls>\n",
    "  <source src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/photography.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      " - The video shows a man in a hat taking pictures of some artifacts on a table.\n",
      "- The man is taking pictures of the artifacts.\n",
      "- #photography, #art, #travel, #vacation, #beach, #sun, #sand, #water, #nature, #explore"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "- What is in the video?\n",
    "- What is the action in the video?\n",
    "- Provide 10 best tags for this video?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/photography.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving extra information beyond the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets ask which all towns are nearby where the car is heading.\n",
    "\n",
    "<video width=\"500\" height=\"500\" controls>\n",
    "  <source src=\"./car_in_mountainous_area.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      " The location is Norway. The road is surrounded by mountains and a lake. The car is driving on a road that is next to a lake. The road is narrow and winding. The car is driving in the direction of the arrow. The nearby towns ahead of the vehicle are:\n",
      "\n",
      "- Geiranger\n",
      "- Hellesylt\n",
      "- Stranda\n",
      "- Sykkylven\n",
      "- Ã…lesund"
     ]
    }
   ],
   "source": [
    "prompt_1 = \"Which location is this?\"\n",
    "prompt_2 = \"Where the lane will lead to the car?\"\n",
    "prompt_3 = \"List all of the nearby towns that is ahead of the vehicle.\"\n",
    "\n",
    "video = convert_file_to_data(\n",
    "    file_path=\"./artifacts/sample_videos/car_in_mountainous_area.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt_1, prompt_2, prompt_3, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_gemini_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
