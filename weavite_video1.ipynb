{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad831/Community_Workshops-/blob/main/weavite_video1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVTvuuckMtP"
      },
      "source": [
        "## Weaviate quickstart guide (as a notebook!)\n",
        "\n",
        "This notebook will guide you through the basics of Weaviate. You can find the full documentation [on our site here](https://weaviate.io/developers/weaviate/quickstart).\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/weaviate-tutorials/quickstart/blob/main/quickstart_end_to_end.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jgIZBZZDpeb-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhV90rankMtQ"
      },
      "source": [
        "You will need the Weaviate Python client. If you don't yet have it installed - you can do so with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRWhefPukMtR"
      },
      "outputs": [],
      "source": [
        "!pip install -U weaviate-client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5_3E4LKkMtR"
      },
      "source": [
        "### Weaviate instance\n",
        "\n",
        "For this, you will need a working instance of Weaviate somewhere. We recommend either:\n",
        "- Creating a free sandbox instance on Weaviate Cloud Services (https://console.weaviate.cloud/), or\n",
        "- Using [Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded).\n",
        "\n",
        "Instantiate the client using **one** of the following code examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI7LBw5skMtS"
      },
      "source": [
        "#### For using WCS\n",
        "\n",
        "NOTE: Before you do this, you need to create the instance in WCS and get the credentials. Please refer to the [WCS Quickstart guide](https://weaviate.io/developers/wcs/quickstart)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzgYvFrlkMtS"
      },
      "outputs": [],
      "source": [
        "# # For using WCS\n",
        "# import weaviate\n",
        "# import json\n",
        "# import os\n",
        "\n",
        "# client = weaviate.Client(\n",
        "#     url = \"https://some-endpoint.weaviate.network\",  # Replace with your endpoint\n",
        "#     auth_client_secret=weaviate.AuthApiKey(api_key=\"YOUR-WEAVIATE-API-KEY\"),  # Replace w/ your Weaviate instance API key\n",
        "#     additional_headers = {\n",
        "#         \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]  # Replace with your inference API key\n",
        "#     }\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX7VeS5hkMtS"
      },
      "source": [
        "#### For using Embedded Weaviate\n",
        "\n",
        "This will spin up a Weaviate instance in the background."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "id": "8XAbMJgvlJze",
        "outputId": "e49b1ca6-e377-4f86-b909-306a65fbc2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m847.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"put your key\"\n",
        "\n",
        "openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Hello ChatGPT, does this work?\"}\n",
        "  ]\n",
        "  )"
      ],
      "metadata": {
        "id": "Ph5dIEvIkqD5",
        "outputId": "84ac5d24-32a5-445a-e2a2-ca9ac2c442db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-98OCcLjlKQ4BnlQQSppVzIEuZ30dg at 0x7dda4800b240> JSON: {\n",
              "  \"id\": \"chatcmpl-98OCcLjlKQ4BnlQQSppVzIEuZ30dg\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1711786686,\n",
              "  \"model\": \"gpt-3.5-turbo-0125\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"Hello! Yes, it works. How can I assist you today?\"\n",
              "      },\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 16,\n",
              "    \"completion_tokens\": 14,\n",
              "    \"total_tokens\": 30\n",
              "  },\n",
              "  \"system_fingerprint\": \"fp_3bc1b5746c\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_APIKEY = openai.api_key"
      ],
      "metadata": {
        "id": "EDxC8qvrmGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_APIKEY"
      ],
      "metadata": {
        "id": "bfgudoR0mJOw",
        "outputId": "b9143a8c-fc52-41e4-8f8a-158ff71340e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UiFHs_CkMtS",
        "outputId": "2ce4821c-63b1-4eef-e8a8-97dd9fc99093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.23.7/weaviate-v1.23.7-Linux-amd64.tar.gz\n",
            "Started /root/.cache/weaviate-embedded: process ID 1263\n"
          ]
        }
      ],
      "source": [
        "# For using embedded\n",
        "import weaviate\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "import json\n",
        "import os\n",
        "\n",
        "client = weaviate.Client(\n",
        "    embedded_options=EmbeddedOptions(),\n",
        "    additional_headers = {\n",
        "        \"X-OpenAI-Api-Key\": openai.api_key # Replace with your inference API key\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utlr1RZnkMtT"
      },
      "source": [
        "### Create a class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLFLqTKnkMtT"
      },
      "outputs": [],
      "source": [
        "if client.schema.exists(\"Question\"):\n",
        "    client.schema.delete_class(\"Question\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQhTCWSTkMtT"
      },
      "outputs": [],
      "source": [
        "class_obj = {\n",
        "    \"class\": \"Question\",\n",
        "    \"vectorizer\": \"text2vec-openai\",  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n",
        "    \"moduleConfig\": {\n",
        "        \"text2vec-openai\": {},\n",
        "        \"generative-openai\": {}  # Ensure the `generative-openai` module is used for generative queries\n",
        "    }\n",
        "}\n",
        "\n",
        "client.schema.create_class(class_obj)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_obj"
      ],
      "metadata": {
        "id": "fXClmqcrmttJ",
        "outputId": "817c4c4b-c079-431d-d679-2312c16c924a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': 'Question',\n",
              " 'vectorizer': 'text2vec-openai',\n",
              " 'moduleConfig': {'text2vec-openai': {}, 'generative-openai': {}}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--4MxRh3kMtU"
      },
      "source": [
        "### Add objects\n",
        "\n",
        "We'll add objects to our Weaviate instance using a batch import process.\n",
        "\n",
        "We shows you two options, where you can either:\n",
        "- Have Weaviate create vectors, or\n",
        "- Specify custom vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgkxG26JkMtU"
      },
      "source": [
        "#### Have Weaviate create vectors (with `text2vec-openai`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsH08hkGkMtU",
        "outputId": "96eb5bc8-aa78-4006-c8a7-a6e2bfa719d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing question: 1\n",
            "importing question: 2\n",
            "importing question: 3\n",
            "importing question: 4\n",
            "importing question: 5\n",
            "importing question: 6\n",
            "importing question: 7\n",
            "importing question: 8\n",
            "importing question: 9\n",
            "importing question: 10\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json'\n",
        "resp = requests.get(url)\n",
        "data = json.loads(resp.text)\n",
        "\n",
        "# Configure a batch process\n",
        "with client.batch(\n",
        "    batch_size=100\n",
        ") as batch:\n",
        "    # Batch import all Questions\n",
        "    for i, d in enumerate(data):\n",
        "        print(f\"importing question: {i+1}\")\n",
        "\n",
        "        properties = {\n",
        "            \"answer\": d[\"Answer\"],\n",
        "            \"question\": d[\"Question\"],\n",
        "            \"category\": d[\"Category\"],\n",
        "        }\n",
        "\n",
        "        client.batch.add_data_object(\n",
        "            properties,\n",
        "            \"Question\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_print(data)"
      ],
      "metadata": {
        "id": "BKqFuKjbpFtM",
        "outputId": "936fad4f-3a81-4e0a-c4da-e9264fe24801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"Category\": \"SCIENCE\",\n",
            "    \"Question\": \"This organ removes excess glucose from the blood & stores it as glycogen\",\n",
            "    \"Answer\": \"Liver\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"ANIMALS\",\n",
            "    \"Question\": \"It's the only living mammal in the order Proboseidea\",\n",
            "    \"Answer\": \"Elephant\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"ANIMALS\",\n",
            "    \"Question\": \"The gavial looks very much like a crocodile except for this bodily feature\",\n",
            "    \"Answer\": \"the nose or snout\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"ANIMALS\",\n",
            "    \"Question\": \"Weighing around a ton, the eland is the largest species of this animal in Africa\",\n",
            "    \"Answer\": \"Antelope\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"ANIMALS\",\n",
            "    \"Question\": \"Heaviest of all poisonous snakes is this North American rattlesnake\",\n",
            "    \"Answer\": \"the diamondback rattler\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"SCIENCE\",\n",
            "    \"Question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\",\n",
            "    \"Answer\": \"species\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"SCIENCE\",\n",
            "    \"Question\": \"A metal that is ductile can be pulled into this while cold & under pressure\",\n",
            "    \"Answer\": \"wire\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"SCIENCE\",\n",
            "    \"Question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\",\n",
            "    \"Answer\": \"DNA\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"SCIENCE\",\n",
            "    \"Question\": \"Changes in the tropospheric layer of this are what gives us weather\",\n",
            "    \"Answer\": \"the atmosphere\"\n",
            "  },\n",
            "  {\n",
            "    \"Category\": \"SCIENCE\",\n",
            "    \"Question\": \"In 70-degree air, a plane traveling at about 1,130 feet per second breaks it\",\n",
            "    \"Answer\": \"Sound barrier\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def json_print(json_data):\n",
        "    import json  # Import the 'json' module\n",
        "    print(json.dumps(json_data, indent=2))  # Pretty-print the JSON\n"
      ],
      "metadata": {
        "id": "xqrmYZVyocdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_print(client.query.aggregate(\"Question\").with_meta_count().do())"
      ],
      "metadata": {
        "id": "vkBmxgxxnKMS",
        "outputId": "f8810e7a-771c-44ca-9fdf-a34fd2b19074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"data\": {\n",
            "    \"Aggregate\": {\n",
            "      \"Question\": [\n",
            "        {\n",
            "          \"meta\": {\n",
            "            \"count\": 10\n",
            "          }\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_print(client.query.get(\"Question\",[\"question\",\"answer\"]).with_limit(3).do())"
      ],
      "metadata": {
        "id": "Cd_Rhxkkoxvf",
        "outputId": "8f7284a5-9634-42cf-b40e-15878dd6bdb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"data\": {\n",
            "    \"Get\": {\n",
            "      \"Question\": [\n",
            "        {\n",
            "          \"answer\": \"DNA\",\n",
            "          \"question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\"\n",
            "        },\n",
            "        {\n",
            "          \"answer\": \"Liver\",\n",
            "          \"question\": \"This organ removes excess glucose from the blood & stores it as glycogen\"\n",
            "        },\n",
            "        {\n",
            "          \"answer\": \"Elephant\",\n",
            "          \"question\": \"It's the only living mammal in the order Proboseidea\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCU70ljkkMtU"
      },
      "source": [
        "#### Specify \"custom\" vectors (i.e. generated outside of Weaviate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLwxTv4XkMtU"
      },
      "outputs": [],
      "source": [
        "# # Load data\n",
        "# import requests\n",
        "# fname = \"jeopardy_tiny_with_vectors_all-OpenAI-ada-002.json\"  # This file includes pre-generated vectors\n",
        "# url = f'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/{fname}'\n",
        "# resp = requests.get(url)\n",
        "# data = json.loads(resp.text)\n",
        "\n",
        "# # Configure a batch process\n",
        "# with client.batch(\n",
        "#     batch_size=100\n",
        "# ) as batch:\n",
        "#     # Batch import all Questions\n",
        "#     for i, d in enumerate(data):\n",
        "#         print(f\"importing question: {i+1}\")\n",
        "\n",
        "#         properties = {\n",
        "#             \"answer\": d[\"Answer\"],\n",
        "#             \"question\": d[\"Question\"],\n",
        "#             \"category\": d[\"Category\"],\n",
        "#         }\n",
        "\n",
        "#         custom_vector = d[\"vector\"]\n",
        "#         client.batch.add_data_object(\n",
        "#             properties,\n",
        "#             \"Question\",\n",
        "#             vector=custom_vector  # Add custom vector\n",
        "#         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GL2QgZDkMtU"
      },
      "source": [
        "### Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNyNpYQWkMtV"
      },
      "source": [
        "#### Semantic search\n",
        "\n",
        "Let's try a similarity search. We'll use nearText search to look for quiz objects most similar to biology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8LNXC3lkMtV",
        "outputId": "b8bf1b95-fc92-46d1-df03-b5872469814b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"data\": {\n",
            "        \"Get\": {\n",
            "            \"Question\": [\n",
            "                {\n",
            "                    \"answer\": \"DNA\",\n",
            "                    \"category\": \"SCIENCE\",\n",
            "                    \"question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\"\n",
            "                },\n",
            "                {\n",
            "                    \"answer\": \"species\",\n",
            "                    \"category\": \"SCIENCE\",\n",
            "                    \"question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "nearText = {\"concepts\": [\"biology\"]}\n",
        "\n",
        "response = (\n",
        "    client.query\n",
        "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
        "    .with_near_text(nearText)\n",
        "    .with_limit(2)\n",
        "    .do()\n",
        ")\n",
        "\n",
        "print(json.dumps(response, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQpYWQkkMtV"
      },
      "source": [
        "The response includes a list of top 2 (due to the limit set) objects whose vectors are most similar to the word biology.\n",
        "\n",
        "Notice that even though the word biology does not appear anywhere, Weaviate returns biology-related entries.\n",
        "\n",
        "This example shows why vector searches are powerful. Vectorized data objects allow for searches based on degrees of similarity, as shown here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWafBeRlkMtV"
      },
      "source": [
        "#### Semantic search with a filter\n",
        "You can add a Boolean filter to your example. For example, let's run the same search, but only look in objects that have a \"category\" value of \"ANIMALS\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umLaYP7ekMtV",
        "outputId": "2017729c-0f33-48e4-b508-574b33479cb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"data\": {\n",
            "        \"Get\": {\n",
            "            \"Question\": [\n",
            "                {\n",
            "                    \"answer\": \"the nose or snout\",\n",
            "                    \"category\": \"ANIMALS\",\n",
            "                    \"question\": \"The gavial looks very much like a crocodile except for this bodily feature\"\n",
            "                },\n",
            "                {\n",
            "                    \"answer\": \"Elephant\",\n",
            "                    \"category\": \"ANIMALS\",\n",
            "                    \"question\": \"It's the only living mammal in the order Proboseidea\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "nearText = {\"concepts\": [\"biology\"]}\n",
        "\n",
        "response = (\n",
        "    client.query\n",
        "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
        "    .with_near_text(nearText)\n",
        "    .with_where({\n",
        "        \"path\": [\"category\"],\n",
        "        \"operator\": \"Equal\",\n",
        "        \"valueText\": \"ANIMALS\"\n",
        "    })\n",
        "    .with_limit(2)\n",
        "    .do()\n",
        ")\n",
        "\n",
        "print(json.dumps(response, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0TBbrDnkMtV"
      },
      "source": [
        "The response includes a list of top 2 (due to the limit set) objects whose vectors are most similar to the word biology - but only from the \"ANIMALS\" category.\n",
        "\n",
        "Using a Boolean filter allows you to combine the flexibility of vector search with the precision of where filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7r0K5rvkMtV"
      },
      "source": [
        "#### Generative search (single prompt)\n",
        "\n",
        "Next, let's try a generative search, where search results are processed with a large language model (LLM).\n",
        "\n",
        "Here, we use a `single prompt` query, and the model to explain each answer in plain terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZqpC3VIkMtV",
        "outputId": "b0c723f9-a67d-413a-de98-746757b0d962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"data\": {\n",
            "        \"Get\": {\n",
            "            \"Question\": [\n",
            "                {\n",
            "                    \"_additional\": {\n",
            "                        \"generate\": {\n",
            "                            \"error\": null,\n",
            "                            \"singleResult\": \"DNA is like a recipe book that tells our bodies how to grow and work. It is made up of tiny instructions that are passed down from our parents and help make us who we are. Just like how a recipe tells you how to make a cake, DNA tells our bodies how to make us!\"\n",
            "                        }\n",
            "                    },\n",
            "                    \"answer\": \"DNA\",\n",
            "                    \"category\": \"SCIENCE\",\n",
            "                    \"question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\"\n",
            "                },\n",
            "                {\n",
            "                    \"_additional\": {\n",
            "                        \"generate\": {\n",
            "                            \"error\": null,\n",
            "                            \"singleResult\": \"A species is a group of living things that are similar to each other and can have babies that are also similar to them. For example, dogs are a species because all dogs look similar and can have puppies that are also dogs.\"\n",
            "                        }\n",
            "                    },\n",
            "                    \"answer\": \"species\",\n",
            "                    \"category\": \"SCIENCE\",\n",
            "                    \"question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\"\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "nearText = {\"concepts\": [\"biology\"]}\n",
        "\n",
        "response = (\n",
        "    client.query\n",
        "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
        "    .with_near_text(nearText)\n",
        "    .with_generate(single_prompt=\"Explain {answer} as you might to a five-year-old.\")\n",
        "    .with_limit(2)\n",
        "    .do()\n",
        ")\n",
        "\n",
        "print(json.dumps(response, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XjH-B-TkMtW"
      },
      "source": [
        "We see that Weaviate has retrieved the same results as before. But now it includes an additional, generated text with a plain-language explanation of each answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw9maIuAkMtW"
      },
      "source": [
        "#### Generative search (grouped task)\n",
        "\n",
        "In the next example, we will use a grouped task prompt instead to combine all search results and send them to the LLM with a prompt. We ask the LLM to write a tweet about all of these search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5qqwbtCkMtW",
        "outputId": "c7bebebe-b121-4375-ab1a-14f3940963aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧬 Did you know? In 1953, Watson & Crick 🧪 built a model of the molecular structure of DNA, the gene-carrying substance! 🧬 #ScienceFacts\n",
            "\n",
            "🐦🌿 Exciting news! In 2000, a new species 🆕 of sage grouse, the Gunnison sage grouse, was discovered. It's not just another northern sage grouse, but a unique classification! 🦆🌿 #ScienceDiscoveries\n"
          ]
        }
      ],
      "source": [
        "response = (\n",
        "    client.query\n",
        "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
        "    .with_near_text({\"concepts\": [\"biology\"]})\n",
        "    .with_generate(grouped_task=\"Write a tweet with emojis about these facts.\")\n",
        "    .with_limit(2)\n",
        "    .do()\n",
        ")\n",
        "\n",
        "print(response[\"data\"][\"Get\"][\"Question\"][0][\"_additional\"][\"generate\"][\"groupedResult\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONha7BjmkMtW"
      },
      "source": [
        "Generative search sends retrieved data from Weaviate to a large language model, or LLM. This allows you to go beyond simple data retrieval, but transform the data into a more useful form, without ever leaving Weaviate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-stEFylkMtW"
      },
      "source": [
        "Well done! In just a few short minutes, you have:\n",
        "\n",
        "- Created your own cloud-based vector database with Weaviate,\n",
        "- Populated it with data objects,\n",
        "    - Using an inference API, or\n",
        "    - Using custom vectors,\n",
        "- Performed searches, including:\n",
        "    - Semantic search,\n",
        "    - Sementic search with a filter and\n",
        "    - Generative search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOeXklf8kMtW"
      },
      "source": [
        "## Next\n",
        "\n",
        "You can do much more with Weaviate. We suggest trying:\n",
        "\n",
        "- Examples from our [search how-to](https://weaviate.io/developers/weaviate/search) guides for [keyword](https://weaviate.io/developers/weaviate/search/bm25), [similarity](https://weaviate.io/developers/weaviate/search/similarity), [hybrid](https://weaviate.io/developers/weaviate/search/hybrid), [generative](https://weaviate.io/developers/weaviate/search/generative) searches and [filters](https://weaviate.io/developers/weaviate/search/filters) or\n",
        "- Learning [how to manage data](https://weaviate.io/developers/weaviate/manage-data), like [reading](https://weaviate.io/developers/weaviate/manage-data/read), [batch importing](https://weaviate.io/developers/weaviate/manage-data/import), [updating](https://weaviate.io/developers/weaviate/manage-data/update), [deleting](https://weaviate.io/developers/weaviate/manage-data/delete) objects or [bulk exporting](https://weaviate.io/developers/weaviate/manage-data/read-all-objects) data.\n",
        "\n",
        "For more holistic learning, try <i class=\"fa-solid fa-graduation-cap\"></i> [Weaviate Academy](https://weaviate.io/developers/academy). We have built free courses for you to learn about Weaviate and the world of vector search.\n",
        "\n",
        "You can also try a larger, [1,000 row](https://raw.githubusercontent.com/databyjp/wv_demo_uploader/main/weaviate_datasets/data/jeopardy_1k.json) version of the Jeopardy! dataset, or [this tiny set of 50 wine reviews](https://raw.githubusercontent.com/databyjp/wv_demo_uploader/main/weaviate_datasets/data/winemag_tiny.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95tf73S4kMtW"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}